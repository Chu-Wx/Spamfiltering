class Vectorizer():
    def __init__(self, max_features):
        self.max_features = max_features
        self.vocab_list = None
        self.token_to_index = None

    def fit(self, dataset):
        from collections import Counter
        Commonlist=(words for line in dataset for words in line)
        tokenlist = Counter(Commonlist)
        Mostcommonword=tokenlist.most_common(max_features)
        self.vocab_list=[i[0] for i in Mostcommonword]
        self.token_to_index={value : index for index, value in enumerate(self.vocab_list)}
          

    def transform(self, dataset):
        data_matrix = np.zeros((len(dataset), len(self.vocab_list)))
        for line_index, line in enumerate(dataset):
          for word_index, word in enumerate(line):
            if word in self.vocab_list:
              word_pos=dataset[line_index][word_index]
              data_matrix[line_index,self.token_to_index[word_pos]]=1
        
        return data_matrix
